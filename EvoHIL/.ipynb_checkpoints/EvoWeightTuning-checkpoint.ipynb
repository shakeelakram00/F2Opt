{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9f758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal Accelerator without Weight Crafting\n",
    "%time !python ./validate.py --dataset=\"5ectopic\" --batchsize=503 --bitfile=finn-accel.bit --runtime_weight_dir=\"runtime_weights/\"    #batchsize=503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c7f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal Throughput without Weight Crafting\n",
    "!python ./driver.py --exec_mode=throughput_test --batchsize=1 --bitfile=finn-accel.bit --runtime_weight_dir=\"runtime_weights/\" --metrics_file=\"N_metrics_file.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e53fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from npytodat_UP import make_weight_file\n",
    "import json\n",
    "import subprocess\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_version(data, percentage, choice):\n",
    "    # Copy the original data to avoid modifying it\n",
    "    new_data = np.copy(data)\n",
    "    \n",
    "    # Calculate how many -1 values should be replaced with 1\n",
    "    num_to_replace = int(num_negative * (percentage / 100))\n",
    "    \n",
    "    if choice == \"Random\":\n",
    "        # Randomly choose indices to replace -1 with 1\n",
    "        indices_to_replace = np.random.choice(num_negative, size=num_to_replace, replace=False)\n",
    "    elif choice == \"AssSeq\":\n",
    "        # Select indices sequentially up to num_to_replace\n",
    "        indices_to_replace = np.arange(num_to_replace)\n",
    "    elif choice == \"DessSeq\":\n",
    "        # Select indices sequentially from the end\n",
    "        indices_to_replace = np.arange(num_negative - 1, num_negative - num_to_replace - 1, -1)\n",
    "    elif choice == \"Diagonal\":\n",
    "        # Start from the middle and expand outward\n",
    "        middle = num_negative // 2\n",
    "        indices_to_replace = []\n",
    "        \n",
    "        # Expand outwards from the middle\n",
    "        for i in range(num_to_replace):\n",
    "            if i % 2 == 0:\n",
    "                indices_to_replace.append(middle + (i // 2))\n",
    "            else:\n",
    "                indices_to_replace.append(middle - (i // 2 + 1)) \n",
    "                \n",
    "    elif choice == \"Alternate\":\n",
    "        # Select every other -1 index\n",
    "        indices_to_replace = np.arange(0, num_negative, step=2)[:num_to_replace]\n",
    "    \n",
    "#     elif choice == \"Checkerboard\":\n",
    "#         # Select indices in a checkerboard pattern\n",
    "#         indices_to_replace = [i for i in range(num_negative) if (i % 2 == 0)][:num_to_replace]\n",
    "    \n",
    "    elif choice == \"Logarithmic\":\n",
    "        # Select indices based on a logarithmic expansion pattern\n",
    "        indices_to_replace = []\n",
    "        step = 1\n",
    "        count = 0\n",
    "        while count < num_to_replace:\n",
    "            indices_to_replace.extend(range(step - 1, min(step * 2 - 1, num_negative)))\n",
    "            step *= 2\n",
    "            count = len(indices_to_replace)\n",
    "        indices_to_replace = indices_to_replace[:num_to_replace]\n",
    "    \n",
    "    elif choice == \"LogarithmicEdge\":\n",
    "        # Logarithmic expansion from the edges toward the center\n",
    "        indices_to_replace = []\n",
    "        left, right = 0, num_negative - 1\n",
    "        step = 1\n",
    "        \n",
    "        while len(indices_to_replace) < num_to_replace:\n",
    "            # Select from left edge\n",
    "            if left < right and len(indices_to_replace) < num_to_replace:\n",
    "                indices_to_replace.extend(range(left, min(left + step, right + 1)))\n",
    "                left += step\n",
    "            \n",
    "            # Select from right edge\n",
    "            if right > left and len(indices_to_replace) < num_to_replace:\n",
    "                indices_to_replace.extend(range(right, max(right - step, left - 1), -1))\n",
    "                right -= step\n",
    "            \n",
    "            step *= 2  # Double the step for logarithmic progression\n",
    "        \n",
    "        indices_to_replace = indices_to_replace[:num_to_replace]  # Trim if overshot\n",
    "    \n",
    "    elif choice == \"Quadrant\":\n",
    "        # Divide the indices into quadrants and select from each quadrant\n",
    "        num_per_quadrant = num_to_replace // 4\n",
    "        indices_to_replace = []\n",
    "        \n",
    "        # Split indices by quadrant and take from each quadrant\n",
    "        for quadrant in range(4):\n",
    "            start_idx = quadrant * (num_negative // 4)\n",
    "            end_idx = start_idx + num_per_quadrant\n",
    "            indices_to_replace.extend(range(start_idx, end_idx))\n",
    "        \n",
    "        # Trim if we selected a bit more due to rounding\n",
    "        indices_to_replace = indices_to_replace[:num_to_replace]\n",
    "        \n",
    "    elif choice == \"RandomCluster\":\n",
    "        # Form clusters of random indices\n",
    "        clusters = 30\n",
    "        cluster_size = max(1, num_to_replace // clusters)  # Divide into roughly 5 clusters\n",
    "        indices_to_replace = []\n",
    "        for _ in range(clusters):\n",
    "            start = np.random.randint(0, num_negative - cluster_size)\n",
    "            indices_to_replace.extend(range(start, start + cluster_size))\n",
    "        indices_to_replace = indices_to_replace[:num_to_replace]\n",
    "        \n",
    "    # Replace the selected -1 values with 1\n",
    "    for idx in indices_to_replace:\n",
    "        # Extract the actual index from the negative_indices array\n",
    "        new_data[negative_indices[0][idx], negative_indices[1][idx]] = 1\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c965b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from npytodat_UP import make_weight_file\n",
    "import json\n",
    "import subprocess\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import shutil \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "Exp = 1\n",
    "choices = [\"Random\", \"AssSeq\", \"DessSeq\", \"Diagonal\", \"Alternate\", \"Logarithmic\", \n",
    "           \"LogarithmicEdge\", \"Quadrant\", \"RandomCluster\"]\n",
    "\n",
    "myChoice = choices[Exp-1]\n",
    "Per_start = 100\n",
    "Per_stop = -1\n",
    "Per_step = -1\n",
    "Acc_initial = 81.652308\n",
    "\n",
    "file_path = 'runtime_ACraftedWeights/'\n",
    "# Load the .json configuration file of FINN for PE and SIMD of layers i.e. matrixvectoractivation\n",
    "with open('A8_pynq_hw_config.json', 'r') as file:\n",
    "    config_data = json.load(file)\n",
    "ACraftedWeight_path = \"runtime_ACraftedWeights/\"  \n",
    "ACraftedWeight_path_npy = f\"EvoWeightTuning_Exp{Exp}_npyPNGcsv/\"\n",
    "os.makedirs(ACraftedWeight_path_npy, exist_ok=True)\n",
    "\n",
    "\n",
    "for file_num in range(1, 7):\n",
    "    file_name = f\"MVA{file_num}.npy\"\n",
    "    data =  np.load(file_path+file_name) #np.random.choice([1, -1], size=[2,10]) #\n",
    "    if file_num == 1:\n",
    "        export_wdt = \"BIPOLAR\"\n",
    "        # Find indices where the values are -1\n",
    "        negative_indices = np.where(data == -1)\n",
    "    else:\n",
    "        export_wdt = \"BINARY\"\n",
    "        # Find indices where the values are -1\n",
    "        negative_indices = np.where(data == 0)\n",
    "    # Number of -1 values in the array\n",
    "    num_negative = len(negative_indices[0])\n",
    "    \n",
    "    csv_file = ACraftedWeight_path_npy+f'MVA{file_num}.csv'\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        file.write(\"Random % SP -1/0 only, Top-1 Test Accuracy\\n\")\n",
    "        \n",
    "    PERcentage = []\n",
    "    Acc = []\n",
    "    \n",
    "    for percentage in range(Per_start, Per_stop, Per_step):\n",
    "        modified_data = create_version(data, percentage, myChoice)  \n",
    "        #Choice== Random/AssSeq/DessSeq/Diagonal/Alternate/Logarithmic/LogarithmicEdge/Quadrant/RandomCluster\n",
    "        #print(f\"{percentage}% of -1 values replaced with 1:\")\n",
    "    \n",
    "        #print(modified_data.shape)\n",
    "        mw, mh = modified_data.shape\n",
    "        pe = config_data.get(f\"MatrixVectorActivation_{file_num-1}\", {}).get(\"PE\", None)\n",
    "        simd = config_data.get(f\"MatrixVectorActivation_{file_num-1}\", {}).get(\"SIMD\", None)\n",
    "        #print(mw, mh, pe, simd)\n",
    "        bw = 1\n",
    "\n",
    "        make_weight_file(modified_data, \"decoupled_runtime\",\n",
    "                         ACraftedWeight_path+f'{file_num}_0_StreamingDataflowPartition_{file_num}_MatrixVectorActivation_0.dat',\n",
    "                         mw, mh, pe, simd,bw, export_wdt)\n",
    "    \n",
    "        command = [\n",
    "        'python', './validate.py', '--dataset=5ectopic', '--batchsize=503', '--bitfile=finn-accel.bit', '--runtime_weight_dir=runtime_ACraftedWeights/']\n",
    "        # Run the command and capture the output\n",
    "        result = subprocess.run(command, stdout=subprocess.PIPE, text=True)\n",
    "        output = result.stdout\n",
    "        #print(\"Accel8_output:\", output)\n",
    "\n",
    "        # Define the CSV file path\n",
    "        # Write output to CSV file\n",
    "        with open(csv_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            # Split the output by lines if it's multiline, or add directly if single line\n",
    "            for line in output.splitlines():\n",
    "                #writer.writerow([line])\n",
    "                writer.writerow([f\"{percentage}\"] + [line])\n",
    "\n",
    "        PERcentage.append(percentage)\n",
    "        Acc.append(round(float(output),4))\n",
    "\n",
    "        ACCURACY = float(output)\n",
    "        if ACCURACY > Acc_initial:\n",
    "            Acc_initial = ACCURACY\n",
    "            np.save(ACraftedWeight_path_npy+f\"{ACCURACY}pC_{file_name}\", modified_data)\n",
    "            print(f\"Percentage (%) Flips: {percentage}% for {ACCURACY}% Accuracy\")\n",
    "    \n",
    "    files = [f for f in os.listdir(ACraftedWeight_path_npy) if f.endswith(f'{file_name}')]\n",
    "    # Sort the files by the creation time (or modification time) in reverse order\n",
    "    files.sort(key=lambda x: os.path.getmtime(os.path.join(ACraftedWeight_path_npy, x)), reverse=True)\n",
    "    # Get the most recently saved file\n",
    "    most_recent_file = files[0] if files else None\n",
    "    # Load the most recent file\n",
    "    if most_recent_file:\n",
    "        recent_data = np.load(os.path.join(ACraftedWeight_path_npy, most_recent_file))\n",
    "        make_weight_file(recent_data, \"decoupled_runtime\",\n",
    "                         ACraftedWeight_path+f'{file_num}_0_StreamingDataflowPartition_{file_num}_MatrixVectorActivation_0.dat',\n",
    "                         mw, mh, pe, simd,bw, export_wdt)\n",
    "    else:\n",
    "        backup_file_path=f\"runtime_weights/{file_num}_0_StreamingDataflowPartition_{file_num}_MatrixVectorActivation_0.dat\"\n",
    "        shutil.copy(backup_file_path, ACraftedWeight_path)\n",
    "    \n",
    "\n",
    "    # Plot the collected data after the loop\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(PERcentage, Acc, linestyle='-', color='b', label='Top-1 Test Accuracy')\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Percentage (%)')\n",
    "    plt.ylabel('Top-1 Test Accuracy (%)')\n",
    "    plt.title('Top-1 Test Accuracy vs. Flip 0/-1 Weights Percentage(%)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.savefig(ACraftedWeight_path_npy+f'MVA_{file_num}.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken to Tune: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e6c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time !python ./validate.py --dataset=\"5ectopic\" --batchsize=503 --bitfile=finn-accel.bit --runtime_weight_dir=\"runtime_ACraftedWeights/\"    #batchsize=503\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9288a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "f_p = ACraftedWeight_path_npy\n",
    "files = [f_p+\"/MVA1e9.csv\", f_p+\"/MVA2.csv\", f_p+\"/MVA3.csv\", f_p+\"/MVA4.csv\", f_p+\"/MVA5.csv\", f_p+\"/MVA6.csv\"]\n",
    "\n",
    "# File names and labels\n",
    "# files = [\"SP_ACraftedWeight_pngAndcsv/MVA1.csv\", \"SP_ACraftedWeight_pngAndcsv/MVA2.csv\", \"SP_ACraftedWeight_pngAndcsv/MVA3.csv\", \n",
    "#          \"SP_ACraftedWeight_pngAndcsv/MVA4.csv\", \"SP_ACraftedWeight_pngAndcsv/MVA5.csv\", \"SP_ACraftedWeight_pngAndcsv/MVA6.csv\"]\n",
    "# files = [\"e14_SP_ACraftedWeight_pngAndcsv/MVA1.csv\", \"e14_SP_ACraftedWeight_pngAndcsv/MVA2.csv\", \"e14_SP_ACraftedWeight_pngAndcsv/MVA3.csv\", \n",
    "#          \"e14_SP_ACraftedWeight_pngAndcsv/MVA4.csv\", \"e14_SP_ACraftedWeight_pngAndcsv/MVA5.csv\", \"e14_SP_ACraftedWeight_pngAndcsv/MVA6.csv\"]\n",
    "labels = [\"MVAU1\", \"MVAU2\", \"MVAU3\", \"MVAU4\", \"MVAU5\", \"MVAU6\"]\n",
    "\n",
    "\n",
    "# Plot each file's data\n",
    "plt.figure(figsize=(8, 5))  # Set figure size\n",
    "\n",
    "for file, label in zip(files, labels):\n",
    "    # Read the CSV file, skip the header row, and separate columns by comma\n",
    "    data = pd.read_csv(file)\n",
    "    \n",
    "    # Extract percentage and accuracy columns\n",
    "    percentage = data.iloc[:, 0]  # First column: percentage\n",
    "    accuracy = data.iloc[:, 1]    # Second column: accuracy\n",
    "    \n",
    "    # Plot each line with a label\n",
    "    plt.plot(percentage, accuracy, marker='o', linestyle='-', label=label)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Percentage (%)\")\n",
    "plt.ylabel(\"Top-1 Test Accuracy (%)\")\n",
    "plt.title(\"Top-1 Test Accuracy vs. Each Layer Flip 0/-1 Weights Percentage(%)\")\n",
    "plt.legend()  # Show the legend with file labels\n",
    "plt.grid(True)  # Add grid for readability\n",
    "plt.savefig(ACraftedWeight_path_npy+f'/Exp{Exp}_MVA1-6.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "# plt.savefig(f'SP_ACraftedWeight_pngAndcsv/e{e}_MVA1-6.png', dpi=600)\n",
    "# plt.savefig(f'e14_SP_ACraftedWeight_pngAndcsv/MVA1-6.png', dpi=600)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc838bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from npytodat_UP import make_weight_file\n",
    "import json\n",
    "import subprocess\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_version(data, percentage, choice):\n",
    "    # Copy the original data to avoid modifying it\n",
    "    new_data = np.copy(data)\n",
    "    \n",
    "    # Calculate how many -1 values should be replaced with 1\n",
    "    num_to_replace = int(num_negative * (percentage / 100))\n",
    "    \n",
    "    if choice == \"Random\":\n",
    "        # Randomly choose indices to replace -1 with 1\n",
    "        indices_to_replace = np.random.choice(num_negative, size=num_to_replace, replace=False)\n",
    "    elif choice == \"AssSeq\":\n",
    "        # Select indices sequentially up to num_to_replace\n",
    "        indices_to_replace = np.arange(num_to_replace)\n",
    "    elif choice == \"DessSeq\":\n",
    "        # Select indices sequentially from the end\n",
    "        indices_to_replace = np.arange(num_negative - 1, num_negative - num_to_replace - 1, -1)\n",
    "    elif choice == \"Diagonal\":\n",
    "        # Start from the middle and expand outward\n",
    "        middle = num_negative // 2\n",
    "        indices_to_replace = []\n",
    "        \n",
    "        # Expand outwards from the middle\n",
    "        for i in range(num_to_replace):\n",
    "            if i % 2 == 0:\n",
    "                indices_to_replace.append(middle + (i // 2))\n",
    "            else:\n",
    "                indices_to_replace.append(middle - (i // 2 + 1)) \n",
    "                \n",
    "    elif choice == \"Alternate\":\n",
    "        # Select every other -1 index\n",
    "        indices_to_replace = np.arange(0, num_negative, step=2)[:num_to_replace]\n",
    "    \n",
    "#     elif choice == \"Checkerboard\":\n",
    "#         # Select indices in a checkerboard pattern\n",
    "#         indices_to_replace = [i for i in range(num_negative) if (i % 2 == 0)][:num_to_replace]\n",
    "    \n",
    "    elif choice == \"Logarithmic\":\n",
    "        # Select indices based on a logarithmic expansion pattern\n",
    "        indices_to_replace = []\n",
    "        step = 1\n",
    "        count = 0\n",
    "        while count < num_to_replace:\n",
    "            indices_to_replace.extend(range(step - 1, min(step * 2 - 1, num_negative)))\n",
    "            step *= 2\n",
    "            count = len(indices_to_replace)\n",
    "        indices_to_replace = indices_to_replace[:num_to_replace]\n",
    "    \n",
    "    elif choice == \"LogarithmicEdge\":\n",
    "        # Logarithmic expansion from the edges toward the center\n",
    "        indices_to_replace = []\n",
    "        left, right = 0, num_negative - 1\n",
    "        step = 1\n",
    "        \n",
    "        while len(indices_to_replace) < num_to_replace:\n",
    "            # Select from left edge\n",
    "            if left < right and len(indices_to_replace) < num_to_replace:\n",
    "                indices_to_replace.extend(range(left, min(left + step, right + 1)))\n",
    "                left += step\n",
    "            \n",
    "            # Select from right edge\n",
    "            if right > left and len(indices_to_replace) < num_to_replace:\n",
    "                indices_to_replace.extend(range(right, max(right - step, left - 1), -1))\n",
    "                right -= step\n",
    "            \n",
    "            step *= 2  # Double the step for logarithmic progression\n",
    "        \n",
    "        indices_to_replace = indices_to_replace[:num_to_replace]  # Trim if overshot\n",
    "    \n",
    "    elif choice == \"Quadrant\":\n",
    "        # Divide the indices into quadrants and select from each quadrant\n",
    "        num_per_quadrant = num_to_replace // 4\n",
    "        indices_to_replace = []\n",
    "        \n",
    "        # Split indices by quadrant and take from each quadrant\n",
    "        for quadrant in range(4):\n",
    "            start_idx = quadrant * (num_negative // 4)\n",
    "            end_idx = start_idx + num_per_quadrant\n",
    "            indices_to_replace.extend(range(start_idx, end_idx))\n",
    "        \n",
    "        # Trim if we selected a bit more due to rounding\n",
    "        indices_to_replace = indices_to_replace[:num_to_replace]\n",
    "        \n",
    "    elif choice == \"RandomCluster\":\n",
    "        # Form clusters of random indices\n",
    "        clusters = 30\n",
    "        cluster_size = max(1, num_to_replace // clusters)  # Divide into roughly 5 clusters\n",
    "        indices_to_replace = []\n",
    "        for _ in range(clusters):\n",
    "            start = np.random.randint(0, num_negative - cluster_size)\n",
    "            indices_to_replace.extend(range(start, start + cluster_size))\n",
    "        indices_to_replace = indices_to_replace[:num_to_replace]\n",
    "        \n",
    "    # Replace the selected -1 values with 1\n",
    "    for idx in indices_to_replace:\n",
    "        # Extract the actual index from the negative_indices array\n",
    "        new_data[negative_indices[0][idx], negative_indices[1][idx]] = 0\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0d35b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from npytodat_UP import make_weight_file\n",
    "import json\n",
    "import subprocess\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import shutil \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "Exp = 1\n",
    "choices = [\"Random\", \"AssSeq\", \"DessSeq\", \"Diagonal\", \"Alternate\", \"Logarithmic\", \n",
    "           \"LogarithmicEdge\", \"Quadrant\", \"RandomCluster\"]\n",
    "\n",
    "myChoice = choices[Exp-1]\n",
    "Per_start = 100\n",
    "Per_stop = -1\n",
    "Per_step = -1\n",
    "Acc_initial = 81.652308\n",
    "\n",
    "file_path = 'runtime_ACraftedWeights/'\n",
    "# Load the .json configuration file of FINN for PE and SIMD of layers i.e. matrixvectoractivation\n",
    "with open('A8_pynq_hw_config.json', 'r') as file:\n",
    "    config_data = json.load(file)\n",
    "ACraftedWeight_path = \"runtime_ACraftedWeights/\"  \n",
    "ACraftedWeight_path_npy = f\"EvoWeightTuning_Exp{Exp}_npyPNGcsv/\"\n",
    "os.makedirs(ACraftedWeight_path_npy, exist_ok=True)\n",
    "\n",
    "\n",
    "for file_num in range(1, 7):\n",
    "    file_name = f\"MVA{file_num}.npy\"\n",
    "    data =  np.load(file_path+file_name) #np.random.choice([1, -1], size=[2,10]) #\n",
    "#     print(data)\n",
    "    if file_num == 1:\n",
    "        export_wdt = \"BIPOLAR\"\n",
    "        # Find indices where the values are -1\n",
    "        negative_indices = np.where(data == 1)\n",
    "#         print(negative_indices)\n",
    "    else:\n",
    "        export_wdt = \"BINARY\"\n",
    "        # Find indices where the values are -1\n",
    "        negative_indices = np.where(data == 1)\n",
    "    # Number of -1 values in the array\n",
    "    num_negative = len(negative_indices[0])\n",
    "    \n",
    "    csv_file = ACraftedWeight_path_npy+f'MVA{file_num}.csv'\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        file.write(\"Random % SP -1/0 only, Top-1 Test Accuracy\\n\")\n",
    "        \n",
    "    PERcentage = []\n",
    "    Acc = []\n",
    "    \n",
    "    for percentage in range(Per_start, Per_stop, Per_step):\n",
    "        modified_data = create_version(data, percentage, myChoice)  \n",
    "        #Choice== Random/AssSeq/DessSeq/Diagonal/Alternate/Logarithmic/LogarithmicEdge/Quadrant/RandomCluster\n",
    "        #print(f\"{percentage}% of -1 values replaced with 1:\")\n",
    "    \n",
    "        #print(modified_data.shape)\n",
    "        mw, mh = modified_data.shape\n",
    "        pe = config_data.get(f\"MatrixVectorActivation_{file_num-1}\", {}).get(\"PE\", None)\n",
    "        simd = config_data.get(f\"MatrixVectorActivation_{file_num-1}\", {}).get(\"SIMD\", None)\n",
    "        #print(mw, mh, pe, simd)\n",
    "        bw = 1\n",
    "\n",
    "        make_weight_file(modified_data, \"decoupled_runtime\",\n",
    "                         ACraftedWeight_path+f'{file_num}_0_StreamingDataflowPartition_{file_num}_MatrixVectorActivation_0.dat',\n",
    "                         mw, mh, pe, simd,bw, export_wdt)\n",
    "        command = [\n",
    "            'python', './validate.py', '--dataset=5ectopic', '--batchsize=503', '--bitfile=finn-accel.bit', '--runtime_weight_dir=runtime_ACraftedWeights/']\n",
    "      \n",
    "        # Run the command and capture the output\n",
    "        result = subprocess.run(command, stdout=subprocess.PIPE, text=True)\n",
    "#         result = subprocess.run(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        output = result.stdout\n",
    "        #print(\"Accel8_output:\", output)\n",
    "\n",
    "        # Define the CSV file path\n",
    "        # Write output to CSV file\n",
    "        with open(csv_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            # Split the output by lines if it's multiline, or add directly if single line\n",
    "            for line in output.splitlines():\n",
    "                #writer.writerow([line])\n",
    "                writer.writerow([f\"{percentage}\"] + [line])\n",
    "#         print(output, \"aa\")\n",
    "\n",
    "        PERcentage.append(percentage)\n",
    "        Acc.append(round(float(output),4))\n",
    "\n",
    "        ACCURACY = float(output)\n",
    "        if ACCURACY > Acc_initial:\n",
    "            Acc_initial = ACCURACY\n",
    "            np.save(ACraftedWeight_path_npy+f\"{ACCURACY}pC_{file_name}\", modified_data)\n",
    "            print(f\"Percentage (%) Flips: {percentage}% for {ACCURACY}% Accuracy\")\n",
    "    \n",
    "    files = [f for f in os.listdir(ACraftedWeight_path_npy) if f.endswith(f'{file_name}')]\n",
    "    # Sort the files by the creation time (or modification time) in reverse order\n",
    "    files.sort(key=lambda x: os.path.getmtime(os.path.join(ACraftedWeight_path_npy, x)), reverse=True)\n",
    "    # Get the most recently saved file\n",
    "    most_recent_file = files[0] if files else None\n",
    "    # Load the most recent file\n",
    "    if most_recent_file:\n",
    "        recent_data = np.load(os.path.join(ACraftedWeight_path_npy, most_recent_file))\n",
    "        make_weight_file(recent_data, \"decoupled_runtime\",\n",
    "                         ACraftedWeight_path+f'{file_num}_0_StreamingDataflowPartition_{file_num}_MatrixVectorActivation_0.dat',\n",
    "                         mw, mh, pe, simd,bw, export_wdt)\n",
    "    else:\n",
    "        backup_file_path=f\"runtime_weights/{file_num}_0_StreamingDataflowPartition_{file_num}_MatrixVectorActivation_0.dat\"\n",
    "        shutil.copy(backup_file_path, ACraftedWeight_path)\n",
    "    \n",
    "\n",
    "    # Plot the collected data after the loop\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(PERcentage, Acc, linestyle='-', color='b', label='Top-1 Test Accuracy')\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Percentage (%)')\n",
    "    plt.ylabel('Top-1 Test Accuracy (%)')\n",
    "    plt.title('Top-1 Test Accuracy vs. Flip 0/-1 Weights Percentage(%)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.savefig(ACraftedWeight_path_npy+f'MVA_{file_num}.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken to Tune: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa97c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7495af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from npytodat_UP import make_weight_file\n",
    "import json\n",
    "import subprocess\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def create_version(data, percentage, choice):\n",
    "    # Copy the original data to avoid modifying it\n",
    "    new_data = np.copy(data)\n",
    "    \n",
    "    # Calculate how many -1 values should be replaced with 1\n",
    "    num_to_replace = int(num_negative * (percentage / 100))\n",
    "    \n",
    "    if choice == \"Random\":\n",
    "        # Randomly choose indices to replace -1 with 1\n",
    "        indices_to_replace = np.random.choice(num_negative, size=num_to_replace, replace=False)\n",
    "    elif choice == \"AssSeq\":\n",
    "        # Select indices sequentially up to num_to_replace\n",
    "        indices_to_replace = np.arange(num_to_replace)\n",
    "    elif choice == \"DessSeq\":\n",
    "        # Select indices sequentially from the end\n",
    "        indices_to_replace = np.arange(num_negative - 1, num_negative - num_to_replace - 1, -1)\n",
    "    elif choice == \"Diagonal\":\n",
    "        # Start from the middle and expand outward\n",
    "        middle = num_negative // 2\n",
    "        indices_to_replace = []\n",
    "        \n",
    "        # Expand outwards from the middle\n",
    "        for i in range(num_to_replace):\n",
    "            if i % 2 == 0:\n",
    "                indices_to_replace.append(middle + (i // 2))\n",
    "            else:\n",
    "                indices_to_replace.append(middle - (i // 2 + 1)) \n",
    "                \n",
    "    elif choice == \"Alternate\":\n",
    "        # Select every other -1 index\n",
    "        indices_to_replace = np.arange(0, num_negative, step=2)[:num_to_replace]\n",
    "    \n",
    "#     elif choice == \"Checkerboard\":\n",
    "#         # Select indices in a checkerboard pattern\n",
    "#         indices_to_replace = [i for i in range(num_negative) if (i % 2 == 0)][:num_to_replace]\n",
    "    \n",
    "    elif choice == \"Logarithmic\":\n",
    "        # Select indices based on a logarithmic expansion pattern\n",
    "        indices_to_replace = []\n",
    "        step = 1\n",
    "        count = 0\n",
    "        while count < num_to_replace:\n",
    "            indices_to_replace.extend(range(step - 1, min(step * 2 - 1, num_negative)))\n",
    "            step *= 2\n",
    "            count = len(indices_to_replace)\n",
    "        indices_to_replace = indices_to_replace[:num_to_replace]\n",
    "    \n",
    "    elif choice == \"LogarithmicEdge\":\n",
    "        # Logarithmic expansion from the edges toward the center\n",
    "        indices_to_replace = []\n",
    "        left, right = 0, num_negative - 1\n",
    "        step = 1\n",
    "        \n",
    "        while len(indices_to_replace) < num_to_replace:\n",
    "            # Select from left edge\n",
    "            if left < right and len(indices_to_replace) < num_to_replace:\n",
    "                indices_to_replace.extend(range(left, min(left + step, right + 1)))\n",
    "                left += step\n",
    "            \n",
    "            # Select from right edge\n",
    "            if right > left and len(indices_to_replace) < num_to_replace:\n",
    "                indices_to_replace.extend(range(right, max(right - step, left - 1), -1))\n",
    "                right -= step\n",
    "            \n",
    "            step *= 2  # Double the step for logarithmic progression\n",
    "        \n",
    "        indices_to_replace = indices_to_replace[:num_to_replace]  # Trim if overshot\n",
    "    \n",
    "    elif choice == \"Quadrant\":\n",
    "        # Divide the indices into quadrants and select from each quadrant\n",
    "        num_per_quadrant = num_to_replace // 4\n",
    "        indices_to_replace = []\n",
    "        \n",
    "        # Split indices by quadrant and take from each quadrant\n",
    "        for quadrant in range(4):\n",
    "            start_idx = quadrant * (num_negative // 4)\n",
    "            end_idx = start_idx + num_per_quadrant\n",
    "            indices_to_replace.extend(range(start_idx, end_idx))\n",
    "        \n",
    "        # Trim if we selected a bit more due to rounding\n",
    "        indices_to_replace = indices_to_replace[:num_to_replace]\n",
    "        \n",
    "    elif choice == \"RandomCluster\":\n",
    "        # Form clusters of random indices\n",
    "        clusters = 30\n",
    "        cluster_size = max(1, num_to_replace // clusters)  # Divide into roughly 5 clusters\n",
    "        indices_to_replace = []\n",
    "        for _ in range(clusters):\n",
    "            start = np.random.randint(0, num_negative - cluster_size)\n",
    "            indices_to_replace.extend(range(start, start + cluster_size))\n",
    "        indices_to_replace = indices_to_replace[:num_to_replace]\n",
    "        \n",
    "    # Replace the selected -1 values with 1\n",
    "    for idx in indices_to_replace:\n",
    "        # Extract the actual index from the negative_indices array\n",
    "        new_data[negative_indices[0][idx], negative_indices[1][idx]] = 1\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee79e2e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from npytodat_UP import make_weight_file\n",
    "import json\n",
    "import subprocess\n",
    "import csv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import shutil \n",
    "\n",
    "start_time = time.time()\n",
    "choices = [\"Random\", \"AssSeq\", \"DessSeq\", \"Diagonal\", \"Alternate\", \"Logarithmic\", \n",
    "           \"LogarithmicEdge\", \"Quadrant\", \"RandomCluster\"]\n",
    "Per_start = 100\n",
    "Per_stop = -1\n",
    "Per_step = -1\n",
    "\n",
    "\n",
    "file_path = 'runtime_ACraftedWeights/'\n",
    "# Load the .json configuration file of FINN for PE and SIMD of layers i.e. matrixvectoractivation\n",
    "with open('A8_pynq_hw_config.json', 'r') as file:\n",
    "    config_data = json.load(file)\n",
    "ACraftedWeight_path = \"runtime_ACraftedWeights/\"  \n",
    "\n",
    "for Exp in range(2, 10):\n",
    "    Acc_initial = 81.652308\n",
    "    if Exp == 8:  # Skip 8\n",
    "        continue\n",
    "    myChoice = choices[Exp-1]\n",
    "    ACraftedWeight_path_npy = f\"EvoWeightTuning_Exp{Exp}_npy_PNGcsv/\"\n",
    "    os.makedirs(ACraftedWeight_path_npy, exist_ok=True)\n",
    "\n",
    "\n",
    "    for file_num in range(1, 7):\n",
    "        file_name = f\"MVA{file_num}.npy\"\n",
    "        data =  np.load(file_path+file_name) #np.random.choice([1, -1], size=[2,10]) #\n",
    "        if file_num == 1:\n",
    "            export_wdt = \"BIPOLAR\"\n",
    "            # Find indices where the values are -1\n",
    "            negative_indices = np.where(data == -1)\n",
    "        else:\n",
    "            export_wdt = \"BINARY\"\n",
    "            # Find indices where the values are -1\n",
    "            negative_indices = np.where(data == 0)\n",
    "        # Number of -1 values in the array\n",
    "        num_negative = len(negative_indices[0])\n",
    "\n",
    "        csv_file = ACraftedWeight_path_npy+f'MVA{file_num}.csv'\n",
    "        with open(csv_file, mode='w', newline='') as file:\n",
    "            file.write(\"Random % SP -1/0 only, Top-1 Test Accuracy\\n\")\n",
    "\n",
    "        PERcentage = []\n",
    "        Acc = []\n",
    "\n",
    "        for percentage in range(Per_start, Per_stop, Per_step):\n",
    "            modified_data = create_version(data, percentage, myChoice)  \n",
    "            #Choice== Random/AssSeq/DessSeq/Diagonal/Alternate/Logarithmic/LogarithmicEdge/Quadrant/RandomCluster\n",
    "            #print(f\"{percentage}% of -1 values replaced with 1:\")\n",
    "\n",
    "            #print(modified_data.shape)\n",
    "            mw, mh = modified_data.shape\n",
    "            pe = config_data.get(f\"MatrixVectorActivation_{file_num-1}\", {}).get(\"PE\", None)\n",
    "            simd = config_data.get(f\"MatrixVectorActivation_{file_num-1}\", {}).get(\"SIMD\", None)\n",
    "            #print(mw, mh, pe, simd)\n",
    "            bw = 1\n",
    "\n",
    "            make_weight_file(modified_data, \"decoupled_runtime\",\n",
    "                             ACraftedWeight_path+f'{file_num}_0_StreamingDataflowPartition_{file_num}_MatrixVectorActivation_0.dat',\n",
    "                             mw, mh, pe, simd,bw, export_wdt)\n",
    "\n",
    "            command = [\n",
    "            'python', './validate.py', '--dataset=5ectopic', '--batchsize=503', '--bitfile=finn-accel.bit', '--runtime_weight_dir=runtime_ACraftedWeights/']\n",
    "            # Run the command and capture the output\n",
    "            result = subprocess.run(command, stdout=subprocess.PIPE, text=True)\n",
    "            output = result.stdout\n",
    "            #print(\"Accel8_output:\", output)\n",
    "\n",
    "            # Define the CSV file path\n",
    "            # Write output to CSV file\n",
    "            with open(csv_file, mode='a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                # Split the output by lines if it's multiline, or add directly if single line\n",
    "                for line in output.splitlines():\n",
    "                    #writer.writerow([line])\n",
    "                    writer.writerow([f\"{percentage}\"] + [line])\n",
    "\n",
    "            PERcentage.append(percentage)\n",
    "            Acc.append(round(float(output),4))\n",
    "\n",
    "            ACCURACY = float(output)\n",
    "            if ACCURACY > Acc_initial:\n",
    "                Acc_initial = ACCURACY\n",
    "                np.save(ACraftedWeight_path_npy+f\"{ACCURACY}pC_{file_name}\", modified_data)\n",
    "                print(f\"Percentage (%) Flips: {percentage}% for {ACCURACY}% Accuracy\")\n",
    "\n",
    "        files = [f for f in os.listdir(ACraftedWeight_path_npy) if f.endswith(f'{file_name}')]\n",
    "        # Sort the files by the creation time (or modification time) in reverse order\n",
    "        files.sort(key=lambda x: os.path.getmtime(os.path.join(ACraftedWeight_path_npy, x)), reverse=True)\n",
    "        # Get the most recently saved file\n",
    "        most_recent_file = files[0] if files else None\n",
    "        # Load the most recent file\n",
    "        if most_recent_file:\n",
    "            recent_data = np.load(os.path.join(ACraftedWeight_path_npy, most_recent_file))\n",
    "            make_weight_file(recent_data, \"decoupled_runtime\",\n",
    "                             ACraftedWeight_path+f'{file_num}_0_StreamingDataflowPartition_{file_num}_MatrixVectorActivation_0.dat',\n",
    "                             mw, mh, pe, simd,bw, export_wdt)\n",
    "        else:\n",
    "            backup_file_path=f\"runtime_weights/{file_num}_0_StreamingDataflowPartition_{file_num}_MatrixVectorActivation_0.dat\"\n",
    "            shutil.copy(backup_file_path, ACraftedWeight_path)\n",
    "\n",
    "\n",
    "        # Plot the collected data after the loop\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(PERcentage, Acc, linestyle='-', color='b', label='Top-1 Test Accuracy')\n",
    "\n",
    "        # Adding labels and title\n",
    "        plt.xlabel('Percentage (%)')\n",
    "        plt.ylabel('Top-1 Test Accuracy (%)')\n",
    "        plt.title('Top-1 Test Accuracy vs. Flip 0/-1 Weights Percentage(%)')\n",
    "        plt.legend()\n",
    "\n",
    "        # Show the plot\n",
    "        plt.grid(True)\n",
    "        plt.savefig(ACraftedWeight_path_npy+f'MVA_{file_num}.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    for dat in range (1, 7):\n",
    "        data_path = ACraftedWeight_path+f'{dat}_0_StreamingDataflowPartition_{dat}_MatrixVectorActivation_0.dat'\n",
    "        shutil.copy(data_path, ACraftedWeight_path_npy)\n",
    "    \n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken to Tune: {elapsed_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
